{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The puspose of this notebook is to create a model and all the features that can help to improve the accuracy of such model.\n",
    "\n",
    "It is been decided to use a Random Forest due to the good results it gives\n",
    "\n",
    "We will follow the following points:\n",
    "\n",
    "1. Create the dataframe\n",
    "2. Times feature engineering\n",
    "3. Lag Variables\n",
    "4. Weather feature engineering\n",
    "5. The function for all the feature engineering\n",
    "6. Model\n",
    "    1. First Model (Random Forest)\n",
    "    2. RandomizedSearchCV Model\n",
    "    3. Test\n",
    "7. Visualization\n",
    "\n",
    "*NOTE: Kindly note that this notebook has been \"cleaned up\" and all the code has been organized for your easy understanding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gonzalo/Repos/TFM/02-EDA'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the preprocessig_v2.py data path\n",
    "cwd = os.getcwd()\n",
    "cwd_list = cwd.split(os.sep)\n",
    "preprocessing_path = os.path.join(os.sep.join(cwd_list[:-1]), '02-EDA')\n",
    "preprocessing_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gonzalo/Repos/TFM/02-EDA\n",
      "/home/gonzalo/Repos/TFM/03-MODEL\n"
     ]
    }
   ],
   "source": [
    "#Import preprocessing_v2\n",
    "%cd $preprocessing_path\n",
    "import preprocessing_v2 as pre\n",
    "%cd $cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please, define the datapath where the data have been unziped**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data path WINDOWS\n",
    "# data_path = os.path.join(os.sep.join(cwd_list[:-1]), 'DATA')\n",
    "# data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gonzalo/Data/TFM/DATA/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define data path LINUX\n",
    "data_path = '/home/gonzalo/Data/TFM/DATA/'\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%[--10%------------------]100%\n",
      "=============================\n",
      "Bicimad_Estacions_201810.json added to DataSet\n",
      "=============================\n",
      "0%[----20%----------------]100%\n",
      "0%[------30%--------------]100%\n",
      "=============================\n",
      "Bicimad_Stations_201901.json added to DataSet\n",
      "=============================\n",
      "0%[--------40%------------]100%\n",
      "0%[----------50%----------]100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-e766cb7bf622>\", line 2, in <module>\n",
      "    df_dock_bikes = pre.make_all_dataset(data_path, 'dock_bikes',by_postal_code=True, verbose=True )\n",
      "  File \"/home/gonzalo/Repos/TFM/02-EDA/preprocessing_v2.py\", line 175, in make_all_dataset\n",
      "    df_aux = pd.read_json(path_aux, lines=True)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/pandas/io/json/json.py\", line 421, in read_json\n",
      "    lines=lines, chunksize=chunksize, compression=compression,\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/pandas/io/json/json.py\", line 471, in __init__\n",
      "    self.data = self._preprocess_data(data)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/pandas/io/json/json.py\", line 482, in _preprocess_data\n",
      "    data = data.read()\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2036, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1379, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1282, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1133, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1071, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1110, in get_records\n",
      "    traceback.print_exc(file=self.ostream)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 163, in print_exc\n",
      "    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 104, in print_exception\n",
      "    type(value), value, tb, limit=limit).format(chain=chain):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 508, in __init__\n",
      "    capture_locals=capture_locals)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 363, in extract\n",
      "    f.line\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 285, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/linecache.py\", line 16, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/linecache.py\", line 137, in updatecache\n",
      "    lines = fp.readlines()\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3313, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2048, in showtraceback\n",
      "    print('\\n' + self.get_exception_only(), file=sys.stderr)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 1993, in get_exception_only\n",
      "    msg = traceback.format_exception_only(etype, value)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 140, in format_exception_only\n",
      "    return list(TracebackException(etype, value, None).format_exception_only())\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 521, in __init__\n",
      "    self._load_lines()\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 533, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 531, in _load_lines\n",
      "    frame.line\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/traceback.py\", line 285, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/linecache.py\", line 16, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/tokenize.py\", line 449, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/tokenize.py\", line 418, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/tokenize.py\", line 376, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/gonzalo/anaconda3/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2032\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2033\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2034\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0;31m# (5 blanks lines) where none should be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_fixed_getinnerframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36m_fixed_getinnerframes\u001b[0;34m(etb, context, tb_offset)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_frame_records_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetinnerframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;31m# If the error is at the console, don't build any context, since it would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetinnerframes\u001b[0;34m(tb, context)\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m         \u001b[0mframeinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0m_filesbymodname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetabsfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;31m# Always map to the name the module knows itself by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetabsfile\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormcase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2035\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2036\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1379\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1282\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1133\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0minspect_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mostream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m             \u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nUnfortunately, your original traceback can not be constructed.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mprint_exc\u001b[0;34m(limit, file, chain)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;34m\"\"\"Shorthand for 'print_exception(*sys.exc_info(), limit, file)'.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mprint_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mprint_exception\u001b[0;34m(etype, value, tb, limit, file, chain)\u001b[0m\n\u001b[1;32m    103\u001b[0m     for line in TracebackException(\n\u001b[0;32m--> 104\u001b[0;31m             type(value), value, tb, limit=limit).format(chain=chain):\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, _seen)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mwalk_tb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookup_lines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             capture_locals=capture_locals)\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/linecache.py\u001b[0m in \u001b[0;36mgetline\u001b[0;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdatecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/linecache.py\u001b[0m in \u001b[0;36mupdatecache\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3312\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3313\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3314\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, exc_tuple)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \"\"\"\n\u001b[1;32m   1992\u001b[0m         \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_exc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mformat_exception_only\u001b[0;34m(etype, value)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTracebackException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, _seen)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36m_load_lines\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36m_load_lines\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;34m\"\"\"Private API. force all lines in the stack to be loaded.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/linecache.py\u001b[0m in \u001b[0;36mgetline\u001b[0;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdatecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mclearcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/linecache.py\u001b[0m in \u001b[0;36mupdatecache\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/tokenize.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_buffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/tokenize.py\u001b[0m in \u001b[0;36mdetect_encoding\u001b[0;34m(readline)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_or_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBOM_UTF8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mbom_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/tokenize.py\u001b[0m in \u001b[0;36mread_or_stop\u001b[0;34m()\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_or_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Load the df_dock_bikes\n",
    "df_dock_bikes = pre.make_all_dataset(data_path, 'dock_bikes',by_postal_code=True, verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load total bases\n",
    "df_total_bases = pre.total_bases_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the occupation rate\n",
    "df_occupation_rate = pre.make_df_occupation_rate(df_dock_bikes, df_total_bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the statistics\n",
    "df_total_bases.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's have a look of the head\n",
    "df_occupation_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the shape\n",
    "df_occupation_rate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's divide the dataset into train, validaton an the other one for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_occupation_rate.iloc[:-2]\n",
    "train.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = df_occupation_rate[-2:-1]\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = df_occupation_rate[-1:]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kindly note that the split is just informative, we will split the dataset before train the model. In the following engineering we will use the train with validations because it is needed the day to predict to get some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Times feature engineering\n",
    "\n",
    "The procedure we are going to follow is the following:\n",
    "\n",
    "- Make the feature day_month, since it may be important to know if we are at the beginning or end of the month.\n",
    "- Make the feature back_days, which will be the number of days between the day to predict and the sample.\n",
    "- Maje the feature weekday which will be divided in two, since in order to keep the information that the sunday is next to monday, we will divide by coordinates where the days of the week will be aroun a circle as a clock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature day of month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's keep the test data (last value) for the test\n",
    "train = df_occupation_rate.iloc[:-1]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check how to get the day of the month\n",
    "print(train.index[2])\n",
    "train.index[2].day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make a new column with the day of the month\n",
    "train['day_month'] = train.index.day\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature backdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the day to predict\n",
    "train.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define the day to predict\n",
    "date_to_predict =  train.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Therefore, the backdays will be:\n",
    "diff_dates = date_to_predict - train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now, it is defined the column with such difference\n",
    "train['back_days'] = diff_dates.days\n",
    "train.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check how to get the day of the week\n",
    "train.index[2].weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now, we define the coordinates of the each day of the week like a clock\n",
    "\n",
    "days_of_week = 7\n",
    "\n",
    "train['sin_weekday'] = np.sin(2*np.pi*train.index.weekday/days_of_week)\n",
    "train['cos_weekday'] = np.cos(2*np.pi*train.index.weekday/days_of_week)\n",
    "\n",
    "train.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we define a function for all the times feature engineering\n",
    "def make_time_features(df):\n",
    "    date_to_predict =  df.index[-1]\n",
    "    diff_dates = date_to_predict - df.index\n",
    "    df['day_month'] = df.index.day\n",
    "    df['back_days'] = diff_dates.days\n",
    "    df['sin_weekday'] = np.sin(2*np.pi*df.index.weekday/7)\n",
    "    df['cos_weekday'] = np.cos(2*np.pi*df.index.weekday/7)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lag Variables\n",
    "\n",
    "In this case we will create a variable of how the occuppation rate was yesterday, 7 days before, and 30 days before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define the function to create such columns\n",
    "def lag_function(df, column):\n",
    "    df[column + '_' + 'lag' + '_' + '1'] = df[column].shift(1)\n",
    "    df[column + '_' + 'lag' + '_' + '7'] = df[column].shift(7)\n",
    "    df[column + '_' + 'lag' + '_' + '30'] = df[column].shift(30)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Filter the columns with the columns we need thed data\n",
    "columns = [x for x in train if 'OccupationRate' in x]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now we apply the functio for each postal code\n",
    "for column in columns:\n",
    "    train = lag_function(train, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's take a look of the train\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As the first days do not have data for the lag, it is decided to fill such NaN with 0, in that way we do not lie to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)\n",
    "train.head(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define function for create the lag variables\n",
    "def bucle_lag_function(df):\n",
    "    columns = [x for x in df if 'OccupationRate' in x]\n",
    "    for column in columns:\n",
    "        df = lag_function(df, column)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Weather feature engineering\n",
    "\n",
    "We are going to use the weather data from AEMET for predicting. In this case, we will use rain, temperature, wind and presure, since they seem the kind of features that can help to predict the usage of the bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the meteo data\n",
    "df_weather = pd.read_json(os.path.join(data_path, 'METEO.txt'))\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make the date column to datetime type\n",
    "df_weather['fecha'] = pd.to_datetime(df_weather['fecha'], format='%Y-%m-%d')\n",
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the columns we want to add to the data set, besides the date\n",
    "selected_columns = ['fecha', 'prec', 'presMax', 'tmed', 'velmedia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Filter the weather data set with such columns\n",
    "df_weather_selected = df_weather[selected_columns]\n",
    "df_weather_selected.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have found a problem, as the decimal separetor of the data is coma and not point pandas do not read such data as a number. Therefore, let's define a function to change such type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_number(x):\n",
    "    try:\n",
    "        x = x.replace(',','.')\n",
    "    except:\n",
    "        x = 0\n",
    "    try:\n",
    "        x = float(x)\n",
    "    except:\n",
    "        x = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And let's apply such function to each column but fecha (date)\n",
    "for column in [x for x in selected_columns if 'fecha' not in x]:\n",
    "    print(column)\n",
    "    df_weather_selected[column] = df_weather_selected[column].apply(convert_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see now the types of data\n",
    "df_weather_selected.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we can merge the weather data with the dataset\n",
    "train = train.merge(df_weather_selected[['fecha', 'prec', 'presMax', 'tmed', 'velmedia']], how='left', left_index=True, right_on='fecha')\n",
    "train.drop('fecha', axis=1, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#As it is seen, somedays it is not recorded the weather data.\n",
    "#It is been decided to fill such data with the value of the last day, since it is the most likely to happen.\n",
    "train[['prec', 'presMax', 'tmed', 'velmedia']].fillna(method='ffill', inplace=True)\n",
    "train[['prec', 'presMax', 'tmed', 'velmedia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's take a look of the dataset\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, let's define the function for add the weather data\n",
    "def make_weather_features(df, df_weather):\n",
    "    df_weather['fecha'] = pd.to_datetime(df_weather['fecha'], format='%Y-%m-%d')\n",
    "    selected_columns = ['fecha', 'prec', 'presMax', 'tmed', 'velmedia']\n",
    "    df_weather_selected = df_weather[selected_columns]\n",
    "    for column in [x for x in selected_columns if 'fecha' not in x]:\n",
    "        df_weather_selected[column] = df_weather_selected[column].apply(convert_to_number)\n",
    "    df = df.merge(df_weather_selected[['fecha', 'prec', 'presMax', 'tmed', 'velmedia']], how='left', left_index=True, right_on='fecha')\n",
    "    df.drop('fecha', axis=1, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df[['prec', 'presMax', 'tmed', 'velmedia']].fillna(method='ffill', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The function for all the feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define a function to do all the feature engineering\n",
    "def feature_engineering(df, df_weather):\n",
    "    df = make_time_features(df)\n",
    "    df = bucle_lag_function(df)\n",
    "    df = make_weather_features(df, df_weather)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data for check the function\n",
    "df_dock_bikes = pre.make_all_dataset(data_path, 'dock_bikes',by_postal_code=True, verbose=False )\n",
    "df_total_bases = pre.total_bases_dataset(data_path)\n",
    "df_occupation_rate = pre.make_df_occupation_rate(df_dock_bikes, df_total_bases)\n",
    "df_test_fun_feature_engineering = df_occupation_rate[:-1]\n",
    "df_test_fun_feature_engineering.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data to check the function\n",
    "df_weather_test_fun_feature_engineering = pd.read_json(os.path.join(data_path, 'METEO.txt'))\n",
    "df_weather_test_fun_feature_engineering.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check the function\n",
    "train_test_fun_feature_engineering = feature_engineering(df_test_fun_feature_engineering, df_weather_test_fun_feature_engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data should be as the same as train dataset\n",
    "np.sum(train_test_fun_feature_engineering.values - train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Choose the columns that correspond to the features\n",
    "columns = train.columns\n",
    "X_columns = [x for x in columns if '28' in x and 'lag' in x]\n",
    "X_columns = X_columns + ['prec', 'presMax', 'tmed', 'velmedia', 'day_month', 'back_days', 'sin_weekday', 'cos_weekday']\n",
    "X_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the columns that correspond to the labels\n",
    "y_columns = [y for y in columns if '28' in y and 'lag' not in y]\n",
    "y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of the validation data\n",
    "X = train.iloc[:-1][X_columns]\n",
    "y = train.iloc[:-1][y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check sizes of the project\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define a function to separate the labels and featueres\n",
    "def get_X_y(df):\n",
    "    columns = df.columns\n",
    "    X_columns = [x for x in columns if '28' in x and 'lag' in x]\n",
    "    X_columns = X_columns + ['prec', 'presMax', 'tmed', 'velmedia', 'day_month', 'back_days', 'sin_weekday', 'cos_weekday']\n",
    "    y_columns = [y for y in columns if '28' in y and 'lag' not in y]\n",
    "    X = df[X_columns]\n",
    "    y = df[y_columns]\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import random forest\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define the first model\n",
    "model = RandomForestRegressor(max_depth=4, n_estimators=50, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the validation data\n",
    "X_validation = train.iloc[-1:][X_columns]\n",
    "y_real = train.iloc[-1:][y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check size of validation data\n",
    "print(X_validation.shape)\n",
    "print(y_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the prediction of the validation data\n",
    "y_predicted_validation = model.predict(X_validation)\n",
    "y_predicted_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get all the metrics together\n",
    "def metrics(y_real, y_predicted):\n",
    "    mae = mean_absolute_error(y_real, y_predicted)\n",
    "    print('MAE: %f' % mae)\n",
    "    mse = mean_squared_error(y_real, y_predicted)\n",
    "    print('MSE: %f' % mse)\n",
    "    rmse = sqrt(mse)\n",
    "    print('RMSE: %f' % rmse)\n",
    "    \n",
    "    return mae, mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get metrics\n",
    "metrics(y_real, y_predicted_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. RandomizedSearchCV Model\n",
    "\n",
    "Now,let's choose the best hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model\n",
    "GridedModel = GridSearchCV(RandomForestRegressor(),\n",
    "                                    param_grid ={'n_estimators' : [10,30,50,80,100,130,150],\n",
    "                                                        'max_depth' : [5,10,15,20,25,30,35,40]},\n",
    "                                    scoring='neg_mean_squared_error',\n",
    "                                    n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the X and y for the grid search\n",
    "X_GridSearch, y_GridSearch = get_X_y(train)\n",
    "print(X_GridSearch.shape, y_GridSearch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "GridedModel.fit(X_GridSearch, y_GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look the best parametrers\n",
    "GridedModel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the best score\n",
    "GridedModel.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best model\n",
    "model_hiper = GridedModel.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load the data including the test\n",
    "df_dock_bikes = pre.make_all_dataset(data_path, 'dock_bikes',by_postal_code=True, verbose=False )\n",
    "df_total_bases = pre.total_bases_dataset(data_path)\n",
    "df_occupation_rate = pre.make_df_occupation_rate(df_dock_bikes, df_total_bases)\n",
    "df_weather = pd.read_json(os.path.join(data_path, 'METEO.txt'))\n",
    "df_test = feature_engineering(df_occupation_rate, df_weather)\n",
    "print(df_test.shape)\n",
    "df_test.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the test data\n",
    "X_test, y_test_real = get_X_y(df_test.iloc[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check shapes\n",
    "print(X_test.shape)\n",
    "print(y_test_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = model_hiper.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics(y_test_real, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "import pickle\n",
    "pickle.dump(model_hiper, open('model', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import altair as alt\n",
    "alt.renderers.enable('notebook')\n",
    "import json\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's open the data of the districts of Madrid\n",
    "with open(os.path.join(data_path, 'distritos.txt')) as f:\n",
    "    data = f.readlines()\n",
    "    data = data[0]\n",
    "    data = json.loads(data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function where add a column saying if such district has bicimad stations\n",
    "def check_barrio(barrio):\n",
    "    barrios_con_estacion = ['MONC','RET','TETU','CENT','CHAMB','CHAMA','SALAM','ARGANZ']\n",
    "    for patron in barrios_con_estacion:\n",
    "        if patron in barrio.upper():\n",
    "            return 'YES'\n",
    "    return 'NOT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonzalo/anaconda3/lib/python3.7/site-packages/geopandas/geodataframe.py:471: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super(GeoDataFrame, self).__getitem__(key)\n"
     ]
    }
   ],
   "source": [
    "#Add such column (if the district has bicimad stations)\n",
    "df_distritos = gpd.GeoDataFrame.from_features((data))\n",
    "df_distritos['barrios_on'] = df_distritos['nombre'].apply(check_barrio)\n",
    "df_distritos_on = df_distritos[df_distritos['barrios_on'] == 'YES']\n",
    "df_distritos_on = df_distritos_on[~df_distritos['nombre'].str.contains(\"cloa\")]\n",
    "distritos = json.loads(df_distritos.to_json())\n",
    "distritos_on = json.loads(df_distritos_on.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cartodb_id</th>\n",
       "      <th>coddistrit</th>\n",
       "      <th>created_at</th>\n",
       "      <th>geometry</th>\n",
       "      <th>nombre</th>\n",
       "      <th>shape_area</th>\n",
       "      <th>shape_len</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>barrios_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>(POLYGON ((-3.664095 40.408523, -3.665152 40.4...</td>\n",
       "      <td>Retiro</td>\n",
       "      <td>5.465317e+06</td>\n",
       "      <td>9523.926778</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>(POLYGON ((-3.697636 40.474539, -3.697495 40.4...</td>\n",
       "      <td>Tetun</td>\n",
       "      <td>5.388122e+06</td>\n",
       "      <td>9925.073151</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>(POLYGON ((-3.693162 40.407345, -3.693202 40.4...</td>\n",
       "      <td>Centro</td>\n",
       "      <td>5.231267e+06</td>\n",
       "      <td>10304.545144</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>(POLYGON ((-3.691222 40.44619, -3.691786 40.44...</td>\n",
       "      <td>Chamber</td>\n",
       "      <td>4.674107e+06</td>\n",
       "      <td>9020.565056</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>(POLYGON ((-3.673616 40.482705, -3.673682 40.4...</td>\n",
       "      <td>Chamartn</td>\n",
       "      <td>9.170135e+06</td>\n",
       "      <td>13401.482255</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>(POLYGON ((-3.659399 40.438273, -3.659592 40.4...</td>\n",
       "      <td>Salamanca</td>\n",
       "      <td>5.387252e+06</td>\n",
       "      <td>10862.998823</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>(POLYGON ((-3.703886 40.405197, -3.702973 40.4...</td>\n",
       "      <td>Arganzuela</td>\n",
       "      <td>6.466406e+06</td>\n",
       "      <td>12834.885747</td>\n",
       "      <td>2015-07-06T13:59:20Z</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cartodb_id coddistrit            created_at  \\\n",
       "6            3          3  2015-07-06T13:59:20Z   \n",
       "8            6          6  2015-07-06T13:59:20Z   \n",
       "9            1          1  2015-07-06T13:59:20Z   \n",
       "10           7          7  2015-07-06T13:59:20Z   \n",
       "11           5          5  2015-07-06T13:59:20Z   \n",
       "12           4          4  2015-07-06T13:59:20Z   \n",
       "13           2          2  2015-07-06T13:59:20Z   \n",
       "\n",
       "                                             geometry      nombre  \\\n",
       "6   (POLYGON ((-3.664095 40.408523, -3.665152 40.4...      Retiro   \n",
       "8   (POLYGON ((-3.697636 40.474539, -3.697495 40.4...      Tetun   \n",
       "9   (POLYGON ((-3.693162 40.407345, -3.693202 40.4...      Centro   \n",
       "10  (POLYGON ((-3.691222 40.44619, -3.691786 40.44...    Chamber   \n",
       "11  (POLYGON ((-3.673616 40.482705, -3.673682 40.4...   Chamartn   \n",
       "12  (POLYGON ((-3.659399 40.438273, -3.659592 40.4...   Salamanca   \n",
       "13  (POLYGON ((-3.703886 40.405197, -3.702973 40.4...  Arganzuela   \n",
       "\n",
       "      shape_area     shape_len            updated_at barrios_on  \n",
       "6   5.465317e+06   9523.926778  2015-07-06T13:59:20Z        YES  \n",
       "8   5.388122e+06   9925.073151  2015-07-06T13:59:20Z        YES  \n",
       "9   5.231267e+06  10304.545144  2015-07-06T13:59:20Z        YES  \n",
       "10  4.674107e+06   9020.565056  2015-07-06T13:59:20Z        YES  \n",
       "11  9.170135e+06  13401.482255  2015-07-06T13:59:20Z        YES  \n",
       "12  5.387252e+06  10862.998823  2015-07-06T13:59:20Z        YES  \n",
       "13  6.466406e+06  12834.885747  2015-07-06T13:59:20Z        YES  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_distritos_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot which districts has bicimad stations\n",
    "source = alt.Data(values=distritos['features'])\n",
    "\n",
    "Madrid = alt.Chart(source).mark_geoshape(\n",
    "        stroke='black',\n",
    "        strokeWidth=1\n",
    ").encode().properties( title=\"Madrid City\"\n",
    "    )\n",
    "\n",
    "barrios_plot = alt.Chart(source).mark_geoshape(\n",
    "        fill='lightgray',\n",
    "        stroke='black'\n",
    "    ).encode(\n",
    "        alt.Color('properties.barrios_on',\n",
    "                  type='ordinal',\n",
    "                  scale=alt.Scale(scheme='tableau10'),\n",
    "                  title='Neighborhood with bike stations')\n",
    "    )\n",
    "\n",
    "Madrid + barrios_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's pivos the data for the plot\n",
    "def pivot_data_frame(df):\n",
    "    df_pivot = pd.DataFrame(columns=['Postal Code', 'Date', 'Occupation Rate'])\n",
    "\n",
    "    columns = df.columns\n",
    "    index = df.index\n",
    "\n",
    "    for column in columns:\n",
    "        for row in index:\n",
    "            aux_dict = {'Postal Code' : [row],\n",
    "                        'Date' : [column],\n",
    "                        'Occupation Rate' : [df.loc[row, column]]\n",
    "                       }\n",
    "            df_aux = pd.DataFrame(aux_dict)\n",
    "            df_pivot = pd.concat([df_pivot, df_aux])\n",
    "    df_pivot.reset_index(inplace=True, drop=True)\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load the data for the plot\n",
    "df_dock_bikes = pre.make_all_dataset(data_path, 'dock_bikes',by_postal_code=True, verbose=False )\n",
    "df_total_bases = pre.total_bases_dataset(data_path)\n",
    "df_occupation_rate = pre.make_df_occupation_rate(df_dock_bikes, df_total_bases)\n",
    "df_weather = pd.read_json(os.path.join(data_path, 'METEO.txt'))\n",
    "df_plot = feature_engineering(df_occupation_rate, df_weather)\n",
    "columns = [x for x in df_plot.columns if '28' in x and not 'lag' in x]\n",
    "df_plot = df_plot[columns]\n",
    "df_plot.columns = [x.split('_')[0] for x in df_plot.columns]\n",
    "df_plot.index = df_occupation_rate.index\n",
    "df_plot = df_plot.T\n",
    "df_plot = pivot_data_frame(df_plot)\n",
    "df_coordinates_postal_codes = pd.read_csv(os.path.join(data_path, 'CoordinatesPostalCodes.csv'), sep=';', dtype={'Codigo Postal' : str})\n",
    "df_coordinates_postal_codes.set_index('Codigo Postal', inplace=True)\n",
    "df_plot = df_plot.merge(df_coordinates_postal_codes, how='left', left_on='Postal Code', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Choose prediction\n",
    "df_plot_prediction = df_plot[df_plot['Date'] == df_plot['Date'].max()]\n",
    "df_plot_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the number of stations by postal code\n",
    "stations_postal_code = pre.load_dict_from_file(data_path)\n",
    "\n",
    "df_stations_postal_code = pd.DataFrame()\n",
    "list_aux = []\n",
    "\n",
    "for postal_code in stations_postal_code:\n",
    "    count_stations = len(stations_postal_code[postal_code])\n",
    "    list_aux.append(count_stations)\n",
    "    df_stations_postal_code[postal_code] = list_aux\n",
    "    list_aux = []\n",
    "    \n",
    "df_stations_postal_code = df_stations_postal_code.T\n",
    "df_stations_postal_code.columns = ['n_stations']\n",
    "df_plot = df_plot.merge(df_stations_postal_code, how='left', left_on='Postal Code', right_index=True)\n",
    "df_plot_prediction = df_plot_prediction.merge(df_stations_postal_code, how='left', left_on='Postal Code', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the dashboard\n",
    "\n",
    "source = alt.Data(values=distritos['features'])\n",
    "source_on = alt.Data(values=distritos_on['features'])\n",
    "\n",
    "width = 750\n",
    "height = 500\n",
    "\n",
    "postal_codes = list(set(df_plot['Postal Code']))\n",
    "postal_codes.sort()\n",
    "postal_codes_selection = alt.binding_select(options=postal_codes)\n",
    "slider_selection = alt.selection_single(bind=postal_codes_selection,\n",
    "                                        fields=['Postal Code'],\n",
    "                                        name=\"Postal Codes\")\n",
    "\n",
    "Madrid = alt.Chart(source).mark_geoshape(\n",
    "        stroke='black',\n",
    "        strokeWidth=1\n",
    ").encode().properties(title=\"Madrid City\",\n",
    "                      width=width/2,\n",
    "                      height=height/2,\n",
    "    )\n",
    "\n",
    "barrios_plot = alt.Chart(source).mark_geoshape(\n",
    "        fill='lightgray',\n",
    "        stroke='black'\n",
    "    ).encode(\n",
    "        alt.Color('properties.barrios_on',\n",
    "                  type='ordinal',\n",
    "                  scale=alt.Scale(scheme='tableau10'),\n",
    "                  title='Neighborhood with bike stations',\n",
    "                 legend=alt.Legend(orient=\"left\"))\n",
    "    )\n",
    "\n",
    "barrios_on = alt.Chart(source_on).mark_geoshape(\n",
    "        stroke='black'\n",
    "    ).encode().properties(title=\"Prediction\",\n",
    "                          width=width/2,\n",
    "                          height=height/2)\n",
    "\n",
    "points = alt.Chart(df_plot).mark_circle().encode(\n",
    "    longitude='Longitud:Q',\n",
    "    latitude='Latitud:Q',\n",
    "    size=alt.Size('n_stations:Q', title='Number of Stations'),\n",
    "    color=alt.Color('Occupation Rate:Q', scale=alt.Scale(scheme=\"spectral\"), title=\"Occupation Rate\"),\n",
    "    tooltip='Occupation Rate:Q'\n",
    ").add_selection(slider_selection).transform_filter(slider_selection)\n",
    "\n",
    "labels = alt.Chart(df_plot_prediction).mark_text(baseline='top'\n",
    "     ).encode(\n",
    "         longitude='Longitud:Q',\n",
    "         latitude='Latitud:Q',\n",
    "         text='Postal Code:O',\n",
    "         size=alt.value(10),\n",
    "         opacity=alt.value(1)\n",
    "     ).transform_filter(slider_selection)\n",
    "\n",
    "time_serie = alt.Chart(df_plot).mark_line().encode(\n",
    "    x='Date:T',\n",
    "    y='Occupation Rate:Q',\n",
    "    tooltip='Occupation Rate:Q'\n",
    ").transform_filter(slider_selection\n",
    ").properties(title='Evolution', width=width, height=height/2\n",
    ")\n",
    "\n",
    "(Madrid + barrios_plot | barrios_on + points + labels) & time_serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df_plot, df_plot_prediction, data_path):\n",
    "    \n",
    "    with open(os.path.join(data_path, 'distritos.txt')) as f:\n",
    "        data = f.readlines()\n",
    "        data = data[0]\n",
    "        data = json.loads(data)\n",
    "        f.close()\n",
    "    \n",
    "    df_distritos = gpd.GeoDataFrame.from_features((data))\n",
    "    df_distritos['barrios_on'] = df_distritos['nombre'].apply(check_barrio)\n",
    "    df_distritos_on = df_distritos[df_distritos['barrios_on'] == 'YES']\n",
    "    df_distritos_on = df_distritos_on[~df_distritos['nombre'].str.contains(\"cloa\")]\n",
    "    distritos = json.loads(df_distritos.to_json())\n",
    "    distritos_on = json.loads(df_distritos_on.to_json())\n",
    "    \n",
    "    source = alt.Data(values=distritos['features'])\n",
    "    source_on = alt.Data(values=distritos_on['features'])\n",
    "\n",
    "    width = 750\n",
    "    height = 500\n",
    "\n",
    "    postal_codes = list(set(df_plot['Postal Code']))\n",
    "    postal_codes.sort()\n",
    "    postal_codes_selection = alt.binding_select(options=postal_codes)\n",
    "    slider_selection = alt.selection_single(bind=postal_codes_selection,\n",
    "                                            fields=['Postal Code'],\n",
    "                                            name=\"Postal Codes\")\n",
    "\n",
    "    Madrid = alt.Chart(source).mark_geoshape(\n",
    "            stroke='black',\n",
    "            strokeWidth=1\n",
    "    ).encode().properties(title=\"Madrid City\",\n",
    "                          width=width/2,\n",
    "                          height=height/2,\n",
    "        )\n",
    "\n",
    "    barrios_plot = alt.Chart(source).mark_geoshape(\n",
    "            fill='lightgray',\n",
    "            stroke='black'\n",
    "        ).encode(\n",
    "            alt.Color('properties.barrios_on',\n",
    "                      type='ordinal',\n",
    "                      scale=alt.Scale(scheme='tableau10'),\n",
    "                      title='Neighborhood with bike stations',\n",
    "                     legend=alt.Legend(orient=\"left\"))\n",
    "        )\n",
    "\n",
    "    barrios_on = alt.Chart(source_on).mark_geoshape(\n",
    "            stroke='black'\n",
    "        ).encode().properties(title=\"Prediction\",\n",
    "                              width=width/2,\n",
    "                              height=height/2)\n",
    "\n",
    "    points = alt.Chart(df_plot).mark_circle().encode(\n",
    "        longitude='Longitud:Q',\n",
    "        latitude='Latitud:Q',\n",
    "        size=alt.Size('n_stations:Q', title='Number of Stations'),\n",
    "        color=alt.Color('Occupation Rate:Q', scale=alt.Scale(scheme=\"spectral\"), title=\"Occupation Rate\"),\n",
    "        tooltip='Occupation Rate:Q'\n",
    "    ).add_selection(slider_selection).transform_filter(slider_selection)\n",
    "\n",
    "    labels = alt.Chart(df_plot_prediction).mark_text(baseline='top'\n",
    "         ).encode(\n",
    "             longitude='Longitud:Q',\n",
    "             latitude='Latitud:Q',\n",
    "             text='Postal Code:O',\n",
    "             size=alt.value(10),\n",
    "             opacity=alt.value(1)\n",
    "         ).transform_filter(slider_selection)\n",
    "\n",
    "    time_serie = alt.Chart(df_plot).mark_line().encode(\n",
    "        x='Date:T',\n",
    "        y='Occupation Rate:Q',\n",
    "        tooltip='Occupation Rate:Q'\n",
    "    ).transform_filter(slider_selection\n",
    "    ).properties(title='Evolution', width=width, height=height/2\n",
    "    )\n",
    "\n",
    "    return (Madrid + barrios_plot | barrios_on + points + labels) & time_serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Plot with postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's open the data of the districts of Madrid\n",
    "with open(os.path.join(data_path, 'MADRID.geojson')) as f:\n",
    "    postal_codes_geo = f.read().splitlines()\n",
    "    postal_codes_geo = \"\".join(postal_codes_geo)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALTA_DB</th>\n",
       "      <th>CODIGO_INE</th>\n",
       "      <th>COD_POSTAL</th>\n",
       "      <th>ID_CP</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015/07/09</td>\n",
       "      <td>28079</td>\n",
       "      <td>28008</td>\n",
       "      <td>2.807900e+11</td>\n",
       "      <td>POLYGON ((-3.718763372131946 40.43541336533451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015/07/09</td>\n",
       "      <td>28082</td>\n",
       "      <td>28410</td>\n",
       "      <td>2.808200e+11</td>\n",
       "      <td>POLYGON ((-3.800949402992558 40.71124645625895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015/07/09</td>\n",
       "      <td>28003</td>\n",
       "      <td>28749</td>\n",
       "      <td>2.800300e+11</td>\n",
       "      <td>POLYGON ((-3.808660970827134 40.88823418785745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015/07/09</td>\n",
       "      <td>28173</td>\n",
       "      <td>28598</td>\n",
       "      <td>2.817300e+11</td>\n",
       "      <td>POLYGON ((-3.257728660948942 40.05274889304695...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015/07/09</td>\n",
       "      <td>28179</td>\n",
       "      <td>28512</td>\n",
       "      <td>2.817900e+11</td>\n",
       "      <td>POLYGON ((-3.288194205198408 40.33271289928086...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ALTA_DB  CODIGO_INE COD_POSTAL         ID_CP  \\\n",
       "0  2015/07/09       28079      28008  2.807900e+11   \n",
       "1  2015/07/09       28082      28410  2.808200e+11   \n",
       "2  2015/07/09       28003      28749  2.800300e+11   \n",
       "3  2015/07/09       28173      28598  2.817300e+11   \n",
       "4  2015/07/09       28179      28512  2.817900e+11   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-3.718763372131946 40.43541336533451...  \n",
       "1  POLYGON ((-3.800949402992558 40.71124645625895...  \n",
       "2  POLYGON ((-3.808660970827134 40.88823418785745...  \n",
       "3  POLYGON ((-3.257728660948942 40.05274889304695...  \n",
       "4  POLYGON ((-3.288194205198408 40.33271289928086...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert string to dict\n",
    "postal_codes_geo_dict = json.loads(postal_codes_geo)\n",
    "\n",
    "#Convert dict into dataframe\n",
    "df_postal_codes = gpd.GeoDataFrame.from_features((postal_codes_geo_dict))\n",
    "df_postal_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for filtering which postal code has stations\n",
    "\n",
    "def check_postal_code(cod_postal):\n",
    "    stations_postal_code_list = ['28013','28004','28015','28005','28008','28014','28012','28001','28009','28007','28006','28046','28045','28010','28003','28020','28002','28036','28016']\n",
    "    for postal_code in stations_postal_code_list:\n",
    "        if postal_code == cod_postal:\n",
    "            return 'YES'\n",
    "    return 'NOT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column if such postal code has bike stations\n",
    "df_postal_codes['pc_on'] = df_postal_codes['COD_POSTAL'].apply(check_postal_code)\n",
    "#Create a dataframe just with the postal codes that have bike stations\n",
    "df_postal_codes_on = df_postal_codes[df_postal_codes['pc_on'] == 'YES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_codes_dict = json.loads(df_postal_codes.to_json())\n",
    "postal_codes_dict_on = json.loads(df_postal_codes_on.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot which districts has bicimad stations\n",
    "source = alt.Data(values=postal_codes_dict['features'])\n",
    "\n",
    "Madrid = alt.Chart(source).mark_geoshape(\n",
    "        stroke='black',\n",
    "        strokeWidth=0.5\n",
    ").encode(\n",
    "        alt.Color('properties.pc_on',\n",
    "                  type='ordinal',\n",
    "                  scale=alt.Scale(scheme='tableau10'),\n",
    "                  title='Postal Codes with bike stations')\n",
    ").properties( title=\"Madrid Postal Codes\"\n",
    "    )\n",
    "\n",
    "Madrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data for the new plot\n",
    "df_dock_bikes = pre.make_all_dataset(data_path, 'dock_bikes',by_postal_code=True, verbose=False )\n",
    "df_total_bases = pre.total_bases_dataset(data_path)\n",
    "df_occupation_rate = pre.make_df_occupation_rate(df_dock_bikes, df_total_bases)\n",
    "df_weather = pd.read_json(os.path.join(data_path, 'METEO.txt'))\n",
    "df_plot = feature_engineering(df_occupation_rate, df_weather)\n",
    "columns = [x for x in df_plot.columns if '28' in x and not 'lag' in x]\n",
    "df_plot = df_plot[columns]\n",
    "df_plot.columns = [x.split('_')[0] for x in df_plot.columns]\n",
    "df_plot.index = df_occupation_rate.index\n",
    "df_plot = df_plot.T\n",
    "df_plot_predic = pd.DataFrame(df_plot[df_plot.columns.max()])\n",
    "df_plot_predic.columns = ['prediction']\n",
    "df_postal_codes_on = df_postal_codes_on.merge(df_plot_predic, left_on='COD_POSTAL', right_index=True)\n",
    "postal_codes_dict_on = json.loads(df_postal_codes_on.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "source = alt.Data(values=postal_codes_dict['features'])\n",
    "source2 = alt.Data(values=postal_codes_dict_on['features'])\n",
    "\n",
    "pcode = alt.selection(type=\"single\", fields=['Postal Code'])\n",
    "\n",
    "Madrid = alt.Chart(source).mark_geoshape(\n",
    "        stroke='black',\n",
    "        strokeWidth=0.5\n",
    ").encode(\n",
    "    alt.Color('properties.pc_on',\n",
    "              type='ordinal',\n",
    "              scale=alt.Scale(scheme='tableau10'),\n",
    "              title='Postal Codes with bike stations',\n",
    "              legend=alt.Legend(orient=\"left\"))\n",
    ").properties(title=\"Madrid Postal Codes\"\n",
    ")\n",
    "\n",
    "Areas = alt.Chart(source2).mark_geoshape(\n",
    "    stroke='black',\n",
    "    strokeWidth=0.5\n",
    ").encode(\n",
    "    alt.Color('properties.prediction:Q',\n",
    "              scale=alt.Scale(scheme='redyellowgreen'))\n",
    ").properties(title=\"Prediction\"\n",
    ").add_selection(pcode)\n",
    "\n",
    "time_serie = alt.Chart(df_plot).mark_line().encode(\n",
    "    x='Date:T',\n",
    "    y='Occupation Rate:Q',\n",
    "    color = alt.Color('Postal Code:N',\n",
    "              scale=alt.Scale(scheme='tableau10')),\n",
    "    tooltip='Occupation Rate:Q'\n",
    ").properties(title='Evolution', width=width, height=height/2\n",
    ").transform_filter(pcode)\n",
    "\n",
    "(Madrid | Areas) & time_serie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
